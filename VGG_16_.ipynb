{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjbv2SUHlZKv1pCLBSemBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navyakarna/PYTORCH_CV/blob/main/VGG_16_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG 16 , VGG 19\n",
        "\n",
        "(MORE POWERFUL THEN ALEXNET , LENET )\n",
        "(16 - LAYERS , WITH LEARNABLE RATES)\n",
        "(CONVOLUTIONAL LAYERS = 13)\n",
        "(RELU = 13 )\n",
        "( IN SET = CONV + RELU)\n",
        "(MAX POOLING = 5 )\n",
        "( FULLY CONNECTED = 3)\n",
        "(SOFTMAX = 1)\n",
        "\n",
        "\n",
        "HIGH DIMENSIONAL INPUTS\n",
        "CONSISTENT FILTER SIZES(ALL 3X3)\n",
        "SMALLER FILTERS ARE ALSO CAPABLE OF CAPTURING FINER DETAILS IN THE IMAGE.\n",
        "\n",
        "PADDING = 1\n",
        "STRIDE = 1\n",
        "\n",
        "EDGES OF THE FEATURE MAP THROUGHOUT THE LAYERS ARE EXTRACTED .\n",
        "\n",
        "\n",
        "SIZE REDUCTION IS DONE THROUGH MAX POOLING (WHERE STRIDE = 2, FILTER 2X2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "VGG 19\n",
        "DEALS WITH 19 LAYERS\n",
        "(19 - LAYERS , WITH LEARNABLE RATES)\n",
        "(CONVOLUTIONAL LAYERS = 16)\n",
        "(RELU = 16 )\n",
        "( IN SET = CONV + RELU)\n",
        "(MAX POOLING = 5 )\n",
        "( FULLY CONNECTED = 3)\n",
        "(SOFTMAX = 1)\n"
      ],
      "metadata": {
        "id": "X5M4xzRPtWo5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cuEP0D57tVQM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import transforms , datasets , models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean =[0.5,0.5,0.5], std=[0.229,0.224, 0.225])\n",
        "\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "YN7i56XMyE03"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile, BadZipFile\n",
        "\n",
        "zip_file_path = '/content/Archive.zip'\n",
        "extract_to_path = '/content/'\n",
        "\n",
        "try:\n",
        "      with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to_path)\n",
        "            print(f\"Extracted files to {extract_to_path}\")\n",
        "except FileNotFoundError:\n",
        "            print(f\"Error: File not found at {zip_file_path}\")\n",
        "except BadZipFile:\n",
        "            print(f\"Error: Invalid or corrupted zip file at {zip_file_path}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBUGXCMkzI3h",
        "outputId": "c22b0051-fe22-409c-e61f-ebd67bb3b66b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted files to /content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder = '/content/Human Action Recognition/train'\n",
        "activity = '/content/Human Action Recognition/train/cycling'\n",
        "img_name = '/content/Human Action Recognition/train/cycling'"
      ],
      "metadata": {
        "id": "eiidgC6n4mz8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = r'/content/Human Action Recognition/train'\n",
        "test_data_path = r'/content/Human Action Recognition/test'"
      ],
      "metadata": {
        "id": "jv5teMhX54fw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(root=train_data_path , transform=transform)\n",
        "test_data = datasets.ImageFolder(root=test_data_path, transform=transform)"
      ],
      "metadata": {
        "id": "sfuDz6M943RD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data , batch_size = 32, shuffle = True, num_workers=4)\n",
        "test_loader = DataLoader(test_data , batch_size = 32, shuffle = True, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2MXVJzy7Ftc",
        "outputId": "29542cf6-6256-44a5-c0e1-9b2cde8f5257"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VCG16(nn.Module):\n",
        "  def __init__ (self, num_classes=5):\n",
        "    super(VCG16, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=3, padding=1 ),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size=3, padding=1 ),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(512 * 7 * 7, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(4096, num_classes),\n",
        "\n",
        "    )\n",
        "\n",
        "    def forward(self, x):\n",
        "       x = self.features(x)\n",
        "       x = x.view(x.size(0), -1)\n",
        "       x = self.classifier(x)\n",
        "       return x\n",
        "\n",
        "\n",
        "model = VCG16(num_classes=5)\n"
      ],
      "metadata": {
        "id": "Fk3Rrcxu7uXb"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}